# Your work for Part 2 here!
# Remember to organize your work by including your own markdown cells!








import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import root_mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import LinearSVR
from sklearn.ensemble import RandomForestRegressor


# Show all columns
pd.set_option('display.max_columns', None)

# Show all rows
pd.set_option('display.max_rows', None)

# Optional: widen display so lines donâ€™t wrap
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)





df = pd.read_csv('../data/cleaned_ameshousing.csv')


df.head()






saleprice_corrs = df.corr(numeric_only=True)[['SalePrice']].sort_values(by='SalePrice', ascending=False)
plt.figure(figsize=(8, 15))
sns.heatmap(saleprice_corrs,
           vmin=-1,
           vmax=1,
           cmap='coolwarm',
           annot=True)









nominal_columns = ['MS SubClass', 'MS Zoning', 'Street', 'Alley', 'Land Contour', 'Lot Config', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', 'Misc Feature', 'Sale Type', 'Sale Condition']


df[nominal_columns] = df[nominal_columns].astype('category')


df_dummy = df[['SalePrice'] + nominal_columns]


df_dummy = pd.get_dummies(df_dummy, columns=nominal_columns)


df_dummy.shape


plt.figure(figsize=(8, 40))
sns.heatmap(df_dummy.corr()[['SalePrice']], 
           vmin=-1,
           vmax=1,
           cmap='coolwarm',
           annot=True)





# list(df.select_dtypes(include=np.number).columns)


features = ['Overall Qual_codes', 'Exter Qual_codes', 'Kitchen Qual_codes', 'Bsmt Qual_codes', \
           'Heating QC_codes', 'Garage Qual_codes', 'Gr Liv Area', \
           'Lot Shape_codes', 'Total Full Bath', 'Total Half Bath', \
           'TotRms AbvGrd', 'Garage Area', 'Overall Cond_codes', 'Misc Val', \
           'Total Bsmt SF', 'Bsmt Cond_codes', 'Garage Area', 'Garage Cond_codes', 'Lot Area']
nominal_features = ['House Style', 'Bldg Type', 'Sale Condition', \
                    'Neighborhood', 'Misc Feature', 'Sale Type', 'Garage Type'] # nominal_columns


len(features + nominal_features)








X = df[features+nominal_features]
y = df['SalePrice']


X = pd.get_dummies(X, columns=nominal_features) #.drop(columns=['Order', 'SalePrice'])


# X.head()


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)








lr = LinearRegression()


lr.fit(X_train, y_train)


def get_scores(model, X_train, X_test, y_train, y_test):
    """
    Creator: Daniel Gallo
    Inputs:
        model: the trained machine learning model on the X_train and y_train created previously. 
        X_train: the features of the training set from train_test_split
        X_test: the feautres of the testing set from train_test_split
        y_train: the targets of the training set from train_test_split
        y_test: the targets of the testing set from train test split
    Outputs: Prints the r-squared score of the models predictions of the training set and testing set
    Creates a baseline RMSE score, as well as RMSE scores for training and testing set. 
    Outputs all the scores for comparison

    Notes:
    Model passed in MUST BE fit to the data prior. train_test_split must also occur BEFORE this method invocation. 
    """
    print(f"Training R-Squared Score:\t{model.score(X_train, y_train)}")
    print(f"Testing R-Squared Score:\t{model.score(X_test, y_test)}")
    train_preds = model.predict(X_train)
    test_preds = model.predict(X_test)
    print(f"Training RMSE Score:\t\t{root_mean_squared_error(y_train, train_preds)}")
    print(f"Testing RMSE Score:\t\t{root_mean_squared_error(y_test, test_preds)}")
    test_mean = y_test.mean()
    baseline_preds = np.full_like(y_test, test_mean)
    print(f"Baseline RMSE Score:\t\t{root_mean_squared_error(y_test, baseline_preds)}")


get_scores(lr, X_train, X_test, y_train, y_test)









alphas = [0.1, 1.0, 10.0, 100.0, 1000.0]
for a in alphas:
    ridge = Ridge(alpha=a)
    ridge.fit(X_train, y_train)
    print(f"Alpha = {a}")
    print('=' * 20)
    get_scores(ridge, X_train, X_test, y_train, y_test)
    print('=' * 20)





alphas = [0.1, 1.0, 10.0, 100.0, 1000.0]
for a in alphas:
    lasso = Lasso(alpha=a)
    lasso.fit(X_train, y_train)
    print(f"Alpha = {a}")
    print('=' * 20)
    get_scores(lasso, X_train, X_test, y_train, y_test)
    print('=' * 20)














coef_df = pd.DataFrame({'Feature': X_train.columns, 'Coef': lr.coef_})
# coef_df


coef_df =coef_df[coef_df['Feature'].isin(features)]


plt.figure(figsize=(16, 18))
sns.barplot(data=coef_df, x='Coef', y='Feature')








rf = RandomForestRegressor()
ls = LinearSVR(max_iter=20000)
dtr = DecisionTreeRegressor()


models = {'Random Forest': rf, 'Linear SVR': ls, 'Decision Tree': dtr}


for name, model in models.items():
    print(name)
    print("=" * 20)
    model.fit(X_train, y_train)
    print()


for name, model in models.items():
    print(name)
    print("=" * 20)
    get_scores(model, X_train, X_test, y_train, y_test)
    print()


df.describe()


y_pred = lr.predict(X_test)


sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual")
plt.ylabel("Predictions")
plt.title("Actual vs Predicted Prices (Linear Regression)")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.tight_layout()
plt.savefig("../images/act_vs_pred_lr.png")


y_pred = rf.predict(X_test)


sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual")
plt.ylabel("Predictions")
plt.title("Actual vs Predicted Prices (Random Forest)")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.tight_layout()
plt.savefig("../images/act_vs_pred_rf.png")



