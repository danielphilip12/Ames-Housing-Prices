import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import root_mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler


# Show all columns
pd.set_option('display.max_columns', None)

# Show all rows
pd.set_option('display.max_rows', None)

# Optional: widen display so lines donâ€™t wrap
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)


plt.rcParams['figure.figsize'] = (10, 5)


df_org = pd.read_csv('../data/cleaned_ameshousing.csv')


df_org.head()


columns = ['Overall Qual_codes', 'Exter Qual_codes', 'Kitchen Qual_codes', 'TotRms AbvGrd', 'Total Full Bath', 'Neighborhood', 'Sale Type', 'House Style', 'SalePrice']


df = df_org[columns]





df.head()


df_dummies = pd.get_dummies(df, columns=['Neighborhood', 'Sale Type', 'House Style']) # for modeling


df.groupby('Neighborhood')['SalePrice'].agg(['mean', 'median', 'count']).sort_values(by=['mean', 'median'], ascending=[False, False])


ax = sns.barplot(data=df, x='Neighborhood', y='SalePrice', errorbar=None)
plt.xticks(rotation=45)
plt.title("Average Sale Price by Neighborhood");


ax = sns.countplot(data=df, x='Neighborhood')
ax.bar_label(ax.containers[0])
plt.xticks(rotation=45)
plt.title("# of Homes in each Neighborhood");


ax = sns.barplot(data=df, x='Neighborhood', y='Overall Qual_codes', errorbar=None)
for container in ax.containers:
    # Use '%.2f' to round the labels to two decimal places
    ax.bar_label(container, fmt='%.2f') 
plt.xticks(rotation=45);


sns.barplot(data=df, x='House Style', y='SalePrice')
plt.xticks(rotation=45);


ax = sns.countplot(data=df, x='House Style')
ax.bar_label(ax.containers[0]);


ax = sns.barplot(data=df, x='House Style', y='Overall Qual_codes', errorbar=None)
for container in ax.containers:
    # Use '%.2f' to round the labels to two decimal places
    ax.bar_label(container, fmt='%.2f') 
plt.xticks(rotation=45);








lr = LinearRegression()
rf = RandomForestRegressor()
dt = DecisionTreeRegressor()


X = df_dummies.drop(columns='SalePrice')
y = df_dummies['SalePrice']


models = {'Linear Regression': lr, 'Random Forest': rf, 'Decision Tree': dt}


sizes = np.arange(0.2, 0.4, 0.01).round(2)
sizes


scores = []
for size in sizes:
    # print(f"Test Size: {size}")
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=size)
    for name, model in models.items():
        model.fit(X_train, y_train)
    # for name, model in models.items():
        # print(f"{name} - {model.score(X_test, y_test)}")
    scores.append({name: model.score(X_test, y_test) for name, model in models.items()})

scores_df = pd.DataFrame(scores)


scores_df['test_size'] = sizes


scores_df



sns.lineplot(data=scores_df, x='test_size', y='Linear Regression', label='Linear Regression', marker='o')
sns.lineplot(data=scores_df, x='test_size', y='Random Forest', label='Random Forest', marker='*')
sns.lineplot(data=scores_df, x='test_size', y='Decision Tree', label='Decision Tree', marker='^')
plt.xticks(sizes);





X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)


sc =StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)


scores = []


for n in range(3, 30, 2):
    knn = KNeighborsRegressor(n_neighbors=n)
    knn.fit(X_train_sc, y_train)
    # print(n)
    scores.append({'neighbors': n, 'score': knn.score(X_test_sc, y_test)})


scores_df = pd.DataFrame(scores)


plt.plot(scores_df['neighbors'], scores_df['score'], marker='o')
plt.xlabel("Neighbors")
plt.ylabel("Score")
plt.xticks(range(3, 30, 2));



