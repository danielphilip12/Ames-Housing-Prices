





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import root_mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler


# Show all columns
pd.set_option('display.max_columns', None)

# Show all rows
pd.set_option('display.max_rows', None)

# Optional: widen display so lines donâ€™t wrap
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)


plt.rcParams['figure.figsize'] = (10, 5)
# sets default size for figures





df_org = pd.read_csv('../data/cleaned_ameshousing.csv')
# imports the original cleaned dataset (before subsetting)


columns = ['Overall Qual_codes', 'Exter Qual_codes', 'Kitchen Qual_codes', 'TotRms AbvGrd', 'Total Full Bath', 'Neighborhood', 'Sale Type', 'House Style', 'SalePrice']
# these are the columns I choose to simplify the model


df = df_org[columns]
# creates the dataframe to use for EDA


df['Overall Qual_codes'] = df['Overall Qual_codes'] + 1
# adjusting this, as the codes were off by 1. Fine for modeling, but not for visualizing 


df.head()
# first 5 rows of the dataframe


df_dummies = pd.get_dummies(df, columns=['Neighborhood', 'Sale Type', 'House Style']) 
# this is for modeling. it makes the dummy variables for the nominal (non-numerical) columns. 





df.groupby('Neighborhood')['SalePrice'].agg(['mean', 'median', 'count']).sort_values(by=['mean', 'median'], ascending=[False, False])
# groups the dataframe by neighborhood, calculating the mean, median, and count for each neighborhood


ax = sns.barplot(data=df, x='Neighborhood', y='SalePrice', errorbar=None)
plt.xticks(rotation=45)
plt.title("Average Sale Price by Neighborhood");
# This creates a barplot of the average sale price by neighborhood





ax = sns.countplot(data=df, x='Neighborhood')
ax.bar_label(ax.containers[0])
plt.xticks(rotation=45)
plt.title("# of Homes in each Neighborhood");
# this makes a countplot of the number of houses in each neighborhood





ax = sns.barplot(data=df, x='Neighborhood', y='Overall Qual_codes', errorbar=None)
for container in ax.containers:
    # Use '%.2f' to round the labels to two decimal places
    ax.bar_label(container, fmt='%.2f') 
plt.title("Average overall quality by Neighborhood")
plt.xticks(rotation=45);
# this makes a barplot of the averagw overall quality of houses in each neighborhood. 





sns.barplot(data=df, x='House Style', y='SalePrice', errorbar=None)
plt.title("Average Sale Price by House Style")
plt.xticks(rotation=45);
# makes a barplot of the average sale price by style of house. 





ax = sns.countplot(data=df, x='House Style')
plt.title("Number of different House Styles")
ax.bar_label(ax.containers[0]);
# makes a countplot of the different house styles





ax = sns.barplot(data=df, x='House Style', y='Overall Qual_codes', errorbar=None)
for container in ax.containers:
    ax.bar_label(container, fmt='%.2f') 
plt.title("Average overall quality by House Style")
plt.xticks(rotation=45);
# creates a barplotof the average overall quality by house style











lr = LinearRegression()
# initializes the linear regression model
rf = RandomForestRegressor()
# initializes the random forest model
dt = DecisionTreeRegressor()
# initializes the decision tree model


X = df_dummies.drop(columns='SalePrice')
# this is our features (with nominal columns as dummy variables)
y = df_dummies['SalePrice']
# this is our target variable


models = {'Linear Regression': lr, 'Random Forest': rf, 'Decision Tree': dt}
# made a dictionary of the models to loop through 


sizes = np.arange(0.2, 0.4, 0.01).round(2)
# different sizes to use for test size


r2_scores = []
# array to store r2 score dictionaries
rmse_scores = []
# array to store rmse score dictionaries
for size in sizes:
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=size)
    # splits the data into training data and test data
    for name, model in models.items():
        model.fit(X_train, y_train)
        # fits each model
    r2_scores.append({name: model.score(X_test, y_test) for name, model in models.items()})
    # appens the r2 score of each model to the r2_scores list
    rmse_score = {}
    for name, model in models.items():
        y_preds = model.predict(X_test)
        # makes prediction 
        y_mean = y_test.mean()
        baseline_preds = np.full_like(y_test, y_mean)
        rmse_score[name] = root_mean_squared_error(y_test, y_preds)
    rmse_score['Baseline'] = root_mean_squared_error(y_test, baseline_preds)
    rmse_scores.append(rmse_score)

r2_scores_df = pd.DataFrame(r2_scores)
rmse_scores_df = pd.DataFrame(rmse_scores)


r2_scores_df['test_size'] = sizes
rmse_scores_df['test_size'] = sizes


rmse_scores_df



sns.lineplot(data=r2_scores_df, x='test_size', y='Linear Regression', label='Linear Regression', marker='o')
sns.lineplot(data=r2_scores_df, x='test_size', y='Random Forest', label='Random Forest', marker='o')
sns.lineplot(data=r2_scores_df, x='test_size', y='Decision Tree', label='Decision Tree', marker='o')
plt.xlabel("Test Size")
plt.ylabel("R-squared Score")
plt.title("R-squared scores at different test sizes")
plt.xticks(sizes);


sns.lineplot(data=rmse_scores_df, x='test_size', y='Linear Regression', label='Linear Regression', marker='o')
sns.lineplot(data=rmse_scores_df, x='test_size', y='Random Forest', label='Random Forest', marker='o')
sns.lineplot(data=rmse_scores_df, x='test_size', y='Decision Tree', label='Decision Tree', marker='o')
sns.lineplot(data=rmse_scores_df, x='test_size', y='Baseline', label='Baseline', marker='o')
plt.xlabel("Test Size")
plt.ylabel("RMSE Score")
plt.title("RMSE scores at different test sizes")
plt.xticks(sizes);
# plt.yticks(range(10000,100000,10000))





X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)


sc =StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)


scores = []


for n in range(3, 30, 2):
    knn = KNeighborsRegressor(n_neighbors=n)
    knn.fit(X_train_sc, y_train)
    # print(n)
    scores.append({'neighbors': n, 'score': knn.score(X_test_sc, y_test)})


scores_df = pd.DataFrame(scores)


plt.plot(scores_df['neighbors'], scores_df['score'], marker='o')
plt.xlabel("Neighbors")
plt.ylabel("Accuracy Score")
plt.title("Accuracy Scores at different K values")
plt.xticks(range(3, 30, 2));



